{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "e1d5f7cc-e69b-4b75-9e49-c42ab70e1f81",
    "_execution_state": "idle",
    "_uuid": "39008a2aa2a73398cb80d8b683bb626b902893e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__MACOSX\r\n",
      "~predict__5300.twbr\r\n",
      "aisles.csv\r\n",
      "data.csv\r\n",
      "data1.csv\r\n",
      "departments.csv\r\n",
      "feature_importance.png\r\n",
      "New folder\r\n",
      "notebook.ipynb\r\n",
      "notebook.py\r\n",
      "order_products__prior.csv\r\n",
      "order_products__train.csv\r\n",
      "orders.csv\r\n",
      "prd.csv\r\n",
      "predict.twb\r\n",
      "products.csv\r\n",
      "python_test.csv\r\n",
      "Rplot001.png\r\n",
      "sample_submission.csv\r\n",
      "sm.csv\r\n",
      "Untitled.ipynb\r\n",
      "us.csv\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "import gc\n",
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../data\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "4449943f-7006-4c6f-a7b4-4bfc24dc1f1a",
    "_execution_state": "idle",
    "_uuid": "043ac17afde77d99e4e69565d3f4c090a6e797bd",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(path_data):\n",
    "    '''\n",
    "    --------------------------------order_product--------------------------------\n",
    "    * Unique in order_id + product_id\n",
    "    '''\n",
    "    priors = pd.read_csv(path_data + 'order_products__prior.csv', \n",
    "                     dtype={\n",
    "                            'order_id': np.int32,\n",
    "                            'product_id': np.uint16,\n",
    "                            'add_to_cart_order': np.int16,\n",
    "                            'reordered': np.int8})\n",
    "    train = pd.read_csv(path_data + 'order_products__train.csv', \n",
    "                    dtype={\n",
    "                            'order_id': np.int32,\n",
    "                            'product_id': np.uint16,\n",
    "                            'add_to_cart_order': np.int16,\n",
    "                            'reordered': np.int8})\n",
    "    '''\n",
    "    --------------------------------order--------------------------------\n",
    "    * This file tells us which set (prior, train, test) an order belongs\n",
    "    * Unique in order_id\n",
    "    * order_id in train, prior, test has no intersection\n",
    "    * this is the #order_number order of this user\n",
    "    '''\n",
    "    orders = pd.read_csv(path_data + 'orders.csv', \n",
    "                         dtype={\n",
    "                                'order_id': np.int32,\n",
    "                                'user_id': np.int64,\n",
    "                                'eval_set': 'category',\n",
    "                                'order_number': np.int16,\n",
    "                                'order_dow': np.int8,\n",
    "                                'order_hour_of_day': np.int8,\n",
    "                                'days_since_prior_order': np.float32})\n",
    "\n",
    "    #  order in prior, train, test has no duplicate\n",
    "    #  order_ids_pri = priors.order_id.unique()\n",
    "    #  order_ids_trn = train.order_id.unique()\n",
    "    #  order_ids_tst = orders[orders.eval_set == 'test']['order_id'].unique()\n",
    "    #  print(set(order_ids_pri).intersection(set(order_ids_trn)))\n",
    "    #  print(set(order_ids_pri).intersection(set(order_ids_tst)))\n",
    "    #  print(set(order_ids_trn).intersection(set(order_ids_tst)))\n",
    "\n",
    "    '''\n",
    "    --------------------------------product--------------------------------\n",
    "    * Unique in product_id\n",
    "    '''\n",
    "    products = pd.read_csv(path_data + 'products.csv')\n",
    "    aisles = pd.read_csv(path_data + \"aisles.csv\")\n",
    "    departments = pd.read_csv(path_data + \"departments.csv\")\n",
    "    sample_submission = pd.read_csv(path_data + \"sample_submission.csv\")\n",
    "    \n",
    "    return priors, train, orders, products, aisles, departments, sample_submission\n",
    "\n",
    "class tick_tock:\n",
    "    def __init__(self, process_name, verbose=1):\n",
    "        self.process_name = process_name\n",
    "        self.verbose = verbose\n",
    "    def __enter__(self):\n",
    "        if self.verbose:\n",
    "            print(self.process_name + \" begin ......\")\n",
    "            self.begin_time = time.time()\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        if self.verbose:\n",
    "            end_time = time.time()\n",
    "            print(self.process_name + \" end ......\")\n",
    "            print('time lapsing {0} s \\n'.format(end_time - self.begin_time))\n",
    "            \n",
    "def ka_add_groupby_features_1_vs_n(df, group_columns_list, agg_dict, only_new_feature=True):\n",
    "    '''Create statistical columns, group by [N columns] and compute stats on [N column]\n",
    "\n",
    "       Parameters\n",
    "       ----------\n",
    "       df: pandas dataframe\n",
    "          Features matrix\n",
    "       group_columns_list: list_like\n",
    "          List of columns you want to group with, could be multiple columns\n",
    "       agg_dict: python dictionary\n",
    "\n",
    "       Return\n",
    "       ------\n",
    "       new pandas dataframe with original columns and new added columns\n",
    "\n",
    "       Example\n",
    "       -------\n",
    "       {real_column_name: {your_specified_new_column_name : method}}\n",
    "       agg_dict = {'user_id':{'prod_tot_cnts':'count'},\n",
    "                   'reordered':{'reorder_tot_cnts_of_this_prod':'sum'},\n",
    "                   'user_buy_product_times': {'prod_order_once':lambda x: sum(x==1),\n",
    "                                              'prod_order_more_than_once':lambda x: sum(x==2)}}\n",
    "       ka_add_stats_features_1_vs_n(train, ['product_id'], agg_dict)\n",
    "    '''\n",
    "    with tick_tock(\"add stats features\"):\n",
    "        try:\n",
    "            if type(group_columns_list) == list:\n",
    "                pass\n",
    "            else:\n",
    "                raise TypeError(k + \"should be a list\")\n",
    "        except TypeError as e:\n",
    "            print(e)\n",
    "            raise\n",
    "\n",
    "        df_new = df.copy()\n",
    "        grouped = df_new.groupby(group_columns_list)\n",
    "\n",
    "        the_stats = grouped.agg(agg_dict)\n",
    "        the_stats.columns = the_stats.columns.droplevel(0)\n",
    "        the_stats.reset_index(inplace=True)\n",
    "        if only_new_feature:\n",
    "            df_new = the_stats\n",
    "        else:\n",
    "            df_new = pd.merge(left=df_new, right=the_stats, on=group_columns_list, how='left')\n",
    "\n",
    "    return df_new\n",
    "\n",
    "def ka_add_groupby_features_n_vs_1(df, group_columns_list, target_columns_list, methods_list, keep_only_stats=True, verbose=1):\n",
    "    '''Create statistical columns, group by [N columns] and compute stats on [1 column]\n",
    "\n",
    "       Parameters\n",
    "       ----------\n",
    "       df: pandas dataframe\n",
    "          Features matrix\n",
    "       group_columns_list: list_like\n",
    "          List of columns you want to group with, could be multiple columns\n",
    "       target_columns_list: list_like\n",
    "          column you want to compute stats, need to be a list with only one element\n",
    "       methods_list: list_like\n",
    "          methods that you want to use, all methods that supported by groupby in Pandas\n",
    "\n",
    "       Return\n",
    "       ------\n",
    "       new pandas dataframe with original columns and new added columns\n",
    "\n",
    "       Example\n",
    "       -------\n",
    "       ka_add_stats_features_n_vs_1(train, group_columns_list=['x0'], target_columns_list=['x10'])\n",
    "    '''\n",
    "    with tick_tock(\"add stats features\", verbose):\n",
    "        dicts = {\"group_columns_list\": group_columns_list , \"target_columns_list\": target_columns_list, \"methods_list\" :methods_list}\n",
    "\n",
    "        for k, v in dicts.items():\n",
    "            try:\n",
    "                if type(v) == list:\n",
    "                    pass\n",
    "                else:\n",
    "                    raise TypeError(k + \"should be a list\")\n",
    "            except TypeError as e:\n",
    "                print(e)\n",
    "                raise\n",
    "\n",
    "        grouped_name = ''.join(group_columns_list)\n",
    "        target_name = ''.join(target_columns_list)\n",
    "        combine_name = [[grouped_name] + [method_name] + [target_name] for method_name in methods_list]\n",
    "\n",
    "        df_new = df.copy()\n",
    "        grouped = df_new.groupby(group_columns_list)\n",
    "\n",
    "        the_stats = grouped[target_name].agg(methods_list).reset_index()\n",
    "        the_stats.columns = [grouped_name] + \\\n",
    "                            ['_%s_%s_by_%s' % (grouped_name, method_name, target_name) \\\n",
    "                             for (grouped_name, method_name, target_name) in combine_name]\n",
    "        if keep_only_stats:\n",
    "            return the_stats\n",
    "        else:\n",
    "            df_new = pd.merge(left=df_new, right=the_stats, on=group_columns_list, how='left')\n",
    "        return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "13b01c67-a0f3-412a-ab62-b49390a494bf",
    "_execution_state": "idle",
    "_uuid": "652ba1d76cc52f7bb8992bc002cd18ced9155ab5"
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-11d7830ee0d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpath_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../data/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpriors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproducts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maisles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepartments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_submission\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-f86eb19acdc9>\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(path_data)\u001b[0m\n\u001b[0;32m     31\u001b[0m                                 \u001b[1;34m'order_dow'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                                 \u001b[1;34m'order_hour_of_day'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m                                 'days_since_prior_order': np.float32})\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m#  order in prior, train, test has no duplicate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 764\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    983\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1605\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas\\_libs\\parsers.c:6175)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header (pandas\\_libs\\parsers.c:9268)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows (pandas\\_libs\\parsers.c:11755)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error (pandas\\_libs\\parsers.c:28765)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "path_data = '../data/'\n",
    "priors, train, orders, products, aisles, departments, sample_submission = load_data(path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "priors_orders_detail = orders.merge(right=priors, how='inner', on='order_id')\n",
    "\n",
    "# create new variables\n",
    "# _user_buy_product_times: 用户是第几次购买该商品\n",
    "priors_orders_detail.loc[:,'_user_buy_product_times'] = priors_orders_detail.groupby(['user_id', 'product_id']).cumcount() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "818ba5dc-48df-4e67-bc80-853a97265964",
    "_execution_state": "idle",
    "_uuid": "d0a7c5706e2fe9e65d9f1f87ae4a6c817bca0049"
   },
   "source": [
    "# Product part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "1d93e83d-8531-43b7-9e1a-5543a350393c",
    "_execution_state": "idle",
    "_uuid": "c9a8c9f490b127ec40674c4e63c2558a09c49c5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add stats features begin ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/pandas/core/groupby.py:4036: FutureWarning: using a dict with renaming is deprecated and will be removed in a future version\n",
      "  return super(DataFrameGroupBy, self).aggregate(arg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add stats features end ......\n",
      "time lapsing 208.06083393096924 s \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Products information ----------------------------------------------------------------\n",
    "# add order information to priors set\n",
    "priors_orders_detail = orders.merge(right=priors, how='inner', on='order_id')\n",
    "\n",
    "# create new variables\n",
    "# _user_buy_product_times: 用户是第几次购买该商品\n",
    "priors_orders_detail.loc[:,'_user_buy_product_times'] = priors_orders_detail.groupby(['user_id', 'product_id']).cumcount() + 1\n",
    "# _prod_tot_cnts: 该商品被购买的总次数,表明被喜欢的程度\n",
    "# _reorder_tot_cnts_of_this_prod: 这件商品被再次购买的总次数\n",
    "### 我觉得下面两个很不好理解，考虑改变++++++++++++++++++++++++++\n",
    "# _prod_order_once: 该商品被购买一次的总次数\n",
    "# _prod_order_more_than_once: 该商品被购买一次以上的总次数\n",
    "agg_dict = {'user_id':{'_prod_tot_cnts':'count'}, \n",
    "            'reordered':{'_prod_reorder_tot_cnts':'sum'}, \n",
    "            '_user_buy_product_times': {'_prod_buy_first_time_total_cnt':lambda x: sum(x==1),\n",
    "                                        '_prod_buy_second_time_total_cnt':lambda x: sum(x==2)}}\n",
    "prd = ka_add_groupby_features_1_vs_n(priors_orders_detail, ['product_id'], agg_dict)\n",
    "\n",
    "# _prod_reorder_prob: 这个指标不好理解\n",
    "# _prod_reorder_ratio: 商品复购率\n",
    "prd['_prod_reorder_prob'] = prd._prod_buy_second_time_total_cnt / prd._prod_buy_first_time_total_cnt\n",
    "prd['_prod_reorder_ratio'] = prd._prod_reorder_tot_cnts / prd._prod_tot_cnts\n",
    "prd['_prod_reorder_times'] = 1 + prd._prod_reorder_tot_cnts / prd._prod_buy_first_time_total_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "876b1e85-103a-4f02-bc82-32c66345be48",
    "_execution_state": "idle",
    "_uuid": "22faa543fec15643fd2e357306b909ceba38bd93"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>_prod_tot_cnts</th>\n",
       "      <th>_prod_buy_first_time_total_cnt</th>\n",
       "      <th>_prod_buy_second_time_total_cnt</th>\n",
       "      <th>_prod_reorder_tot_cnts</th>\n",
       "      <th>_prod_reorder_prob</th>\n",
       "      <th>_prod_reorder_ratio</th>\n",
       "      <th>_prod_reorder_times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1852</td>\n",
       "      <td>716</td>\n",
       "      <td>276</td>\n",
       "      <td>1136.0</td>\n",
       "      <td>0.385475</td>\n",
       "      <td>0.613391</td>\n",
       "      <td>2.586592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>78</td>\n",
       "      <td>8</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>277</td>\n",
       "      <td>74</td>\n",
       "      <td>36</td>\n",
       "      <td>203.0</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>0.732852</td>\n",
       "      <td>3.743243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>329</td>\n",
       "      <td>182</td>\n",
       "      <td>64</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.351648</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>1.807692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  _prod_tot_cnts  _prod_buy_first_time_total_cnt  \\\n",
       "0           1            1852                             716   \n",
       "1           2              90                              78   \n",
       "2           3             277                              74   \n",
       "3           4             329                             182   \n",
       "4           5              15                               6   \n",
       "\n",
       "   _prod_buy_second_time_total_cnt  _prod_reorder_tot_cnts  \\\n",
       "0                              276                  1136.0   \n",
       "1                                8                    12.0   \n",
       "2                               36                   203.0   \n",
       "3                               64                   147.0   \n",
       "4                                4                     9.0   \n",
       "\n",
       "   _prod_reorder_prob  _prod_reorder_ratio  _prod_reorder_times  \n",
       "0            0.385475             0.613391             2.586592  \n",
       "1            0.102564             0.133333             1.153846  \n",
       "2            0.486486             0.732852             3.743243  \n",
       "3            0.351648             0.446809             1.807692  \n",
       "4            0.666667             0.600000             2.500000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prd.to_csv('prd.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4e57204c-f54e-4f6b-8962-9a1a86391df8",
    "_execution_state": "idle",
    "_uuid": "e6bb6010c3d614f8a61cd8cfc0cafdf91f60ac98"
   },
   "source": [
    "# User Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "0d7e8b5d-96f2-4fde-b915-2e4eb5948747",
    "_execution_state": "busy",
    "_uuid": "2caadb329254e7e3f20383847e0d75485662a913"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add stats features begin ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/pandas/core/groupby.py:4036: FutureWarning: using a dict with renaming is deprecated and will be removed in a future version\n",
      "  return super(DataFrameGroupBy, self).aggregate(arg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add stats features end ......\n",
      "time lapsing 0.32972240447998047 s \n",
      "\n",
      "add stats features begin ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:15: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add stats features end ......\n",
      "time lapsing 884.2385692596436 s \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# _user_total_orders: 用户的总订单数\n",
    "# 可以考虑加入其它统计指标++++++++++++++++++++++++++\n",
    "# _user_sum_days_since_prior_order: 距离上次购买时间(和),这个只能在orders表里面计算，priors_orders_detail不是在order level上面unique\n",
    "# _user_mean_days_since_prior_order: 距离上次购买时间(均值)\n",
    "agg_dict_2 = {'order_number':{'_user_total_orders':'max'},\n",
    "              'days_since_prior_order':{'_user_sum_days_since_prior_order':'sum', \n",
    "                                        '_user_mean_days_since_prior_order': 'mean'}}\n",
    "users = ka_add_groupby_features_1_vs_n(orders[orders.eval_set == 'prior'], ['user_id'], agg_dict_2)\n",
    "\n",
    "# _user_reorder_ratio: reorder的总次数 / 第一单后买后的总次数\n",
    "# _user_total_products: 用户购买的总商品数\n",
    "# _user_distinct_products: 用户购买的unique商品数\n",
    "agg_dict_3 = {'reordered':\n",
    "              {'_user_reorder_ratio': \n",
    "               lambda x: sum(priors_orders_detail.ix[x.index,'reordered']==1)/\n",
    "                         sum(priors_orders_detail.ix[x.index,'order_number'] > 1)},\n",
    "              'product_id':{'_user_total_products':'count', \n",
    "                            '_user_distinct_products': lambda x: x.nunique()}}\n",
    "us = ka_add_groupby_features_1_vs_n(priors_orders_detail, ['user_id'], agg_dict_3)\n",
    "users = users.merge(us, how='inner')\n",
    "\n",
    "# 平均每单的商品数\n",
    "# 每单中最多的商品数，最少的商品数++++++++++++++\n",
    "users['_user_average_basket'] = users._user_total_products / users._user_total_orders\n",
    "\n",
    "us = orders[orders.eval_set != \"prior\"][['user_id', 'order_id', 'eval_set', 'days_since_prior_order']]\n",
    "us.rename(index=str, columns={'days_since_prior_order': 'time_since_last_order'}, inplace=True)\n",
    "\n",
    "users = users.merge(us, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "10f6d636-8ca5-4c75-ac38-ee2e9a2d4a76",
    "_execution_state": "busy",
    "_uuid": "9747c3e86c1eafbd0601879c667274e3d7b96e78"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>_user_total_orders</th>\n",
       "      <th>_user_sum_days_since_prior_order</th>\n",
       "      <th>_user_mean_days_since_prior_order</th>\n",
       "      <th>_user_distinct_products</th>\n",
       "      <th>_user_total_products</th>\n",
       "      <th>_user_reorder_ratio</th>\n",
       "      <th>_user_average_basket</th>\n",
       "      <th>order_id</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>time_since_last_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>176.0</td>\n",
       "      <td>19.555555</td>\n",
       "      <td>18</td>\n",
       "      <td>59</td>\n",
       "      <td>0.759259</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>1187899</td>\n",
       "      <td>train</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>198.0</td>\n",
       "      <td>15.230769</td>\n",
       "      <td>102</td>\n",
       "      <td>195</td>\n",
       "      <td>0.510989</td>\n",
       "      <td>13.928571</td>\n",
       "      <td>1492625</td>\n",
       "      <td>train</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>133.0</td>\n",
       "      <td>12.090909</td>\n",
       "      <td>33</td>\n",
       "      <td>88</td>\n",
       "      <td>0.705128</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>2774568</td>\n",
       "      <td>test</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>329954</td>\n",
       "      <td>test</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>23</td>\n",
       "      <td>37</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>2196797</td>\n",
       "      <td>train</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  _user_total_orders  _user_sum_days_since_prior_order  \\\n",
       "0        1                  10                             176.0   \n",
       "1        2                  14                             198.0   \n",
       "2        3                  12                             133.0   \n",
       "3        4                   5                              55.0   \n",
       "4        5                   4                              40.0   \n",
       "\n",
       "   _user_mean_days_since_prior_order  _user_distinct_products  \\\n",
       "0                          19.555555                       18   \n",
       "1                          15.230769                      102   \n",
       "2                          12.090909                       33   \n",
       "3                          13.750000                       17   \n",
       "4                          13.333333                       23   \n",
       "\n",
       "   _user_total_products  _user_reorder_ratio  _user_average_basket  order_id  \\\n",
       "0                    59             0.759259              5.900000   1187899   \n",
       "1                   195             0.510989             13.928571   1492625   \n",
       "2                    88             0.705128              7.333333   2774568   \n",
       "3                    18             0.071429              3.600000    329954   \n",
       "4                    37             0.538462              9.250000   2196797   \n",
       "\n",
       "  eval_set  time_since_last_order  \n",
       "0    train                   14.0  \n",
       "1    train                   30.0  \n",
       "2     test                   11.0  \n",
       "3     test                   30.0  \n",
       "4    train                    6.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users.to_csv('us.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>_prod_buy_second_time_total_cnt</th>\n",
       "      <th>_prod_buy_first_time_total_cnt</th>\n",
       "      <th>_prod_reorder_tot_cnts</th>\n",
       "      <th>_prod_tot_cnts</th>\n",
       "      <th>_prod_reorder_prob</th>\n",
       "      <th>_prod_reorder_ratio</th>\n",
       "      <th>_prod_reorder_times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>276</td>\n",
       "      <td>716</td>\n",
       "      <td>1136.0</td>\n",
       "      <td>1852</td>\n",
       "      <td>0.385475</td>\n",
       "      <td>0.613391</td>\n",
       "      <td>2.586592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>78</td>\n",
       "      <td>12.0</td>\n",
       "      <td>90</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>74</td>\n",
       "      <td>203.0</td>\n",
       "      <td>277</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>0.732852</td>\n",
       "      <td>3.743243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>182</td>\n",
       "      <td>147.0</td>\n",
       "      <td>329</td>\n",
       "      <td>0.351648</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>1.807692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  _prod_buy_second_time_total_cnt  \\\n",
       "0           1                              276   \n",
       "1           2                                8   \n",
       "2           3                               36   \n",
       "3           4                               64   \n",
       "4           5                                4   \n",
       "\n",
       "   _prod_buy_first_time_total_cnt  _prod_reorder_tot_cnts  _prod_tot_cnts  \\\n",
       "0                             716                  1136.0            1852   \n",
       "1                              78                    12.0              90   \n",
       "2                              74                   203.0             277   \n",
       "3                             182                   147.0             329   \n",
       "4                               6                     9.0              15   \n",
       "\n",
       "   _prod_reorder_prob  _prod_reorder_ratio  _prod_reorder_times  \n",
       "0            0.385475             0.613391             2.586592  \n",
       "1            0.102564             0.133333             1.153846  \n",
       "2            0.486486             0.732852             3.743243  \n",
       "3            0.351648             0.446809             1.807692  \n",
       "4            0.666667             0.600000             2.500000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prd=pd.read_csv('prd.csv')\n",
    "\n",
    "prd=prd.iloc[:,1:10]\n",
    "prd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>_user_sum_days_since_prior_order</th>\n",
       "      <th>_user_mean_days_since_prior_order</th>\n",
       "      <th>_user_total_orders</th>\n",
       "      <th>_user_distinct_products</th>\n",
       "      <th>_user_total_products</th>\n",
       "      <th>_user_reorder_ratio</th>\n",
       "      <th>_user_average_basket</th>\n",
       "      <th>order_id</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>time_since_last_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>176.0</td>\n",
       "      <td>19.555555</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>59</td>\n",
       "      <td>0.759259</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>1187899</td>\n",
       "      <td>train</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>198.0</td>\n",
       "      <td>15.230769</td>\n",
       "      <td>14</td>\n",
       "      <td>102</td>\n",
       "      <td>195</td>\n",
       "      <td>0.510989</td>\n",
       "      <td>13.928571</td>\n",
       "      <td>1492625</td>\n",
       "      <td>train</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>133.0</td>\n",
       "      <td>12.090909</td>\n",
       "      <td>12</td>\n",
       "      <td>33</td>\n",
       "      <td>88</td>\n",
       "      <td>0.705128</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>2774568</td>\n",
       "      <td>test</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>55.0</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>329954</td>\n",
       "      <td>test</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>37</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>2196797</td>\n",
       "      <td>train</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  _user_sum_days_since_prior_order  \\\n",
       "0        1                             176.0   \n",
       "1        2                             198.0   \n",
       "2        3                             133.0   \n",
       "3        4                              55.0   \n",
       "4        5                              40.0   \n",
       "\n",
       "   _user_mean_days_since_prior_order  _user_total_orders  \\\n",
       "0                          19.555555                  10   \n",
       "1                          15.230769                  14   \n",
       "2                          12.090909                  12   \n",
       "3                          13.750000                   5   \n",
       "4                          13.333333                   4   \n",
       "\n",
       "   _user_distinct_products  _user_total_products  _user_reorder_ratio  \\\n",
       "0                       18                    59             0.759259   \n",
       "1                      102                   195             0.510989   \n",
       "2                       33                    88             0.705128   \n",
       "3                       17                    18             0.071429   \n",
       "4                       23                    37             0.538462   \n",
       "\n",
       "   _user_average_basket  order_id eval_set  time_since_last_order  \n",
       "0              5.900000   1187899    train                   14.0  \n",
       "1             13.928571   1492625    train                   30.0  \n",
       "2              7.333333   2774568     test                   11.0  \n",
       "3              3.600000    329954     test                   30.0  \n",
       "4              9.250000   2196797    train                    6.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users=pd.read_csv('us.csv')\n",
    "\n",
    "users=users.iloc[:,1:13]\n",
    "users.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206209, 11)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add stats features begin ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/pandas/core/groupby.py:4036: FutureWarning: using a dict with renaming is deprecated and will be removed in a future version\n",
      "  return super(DataFrameGroupBy, self).aggregate(arg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add stats features end ......\n",
      "time lapsing 16.190242290496826 s \n",
      "\n"
     ]
    }
   ],
   "source": [
    "agg_dict_4 = {'order_number':{'_up_order_count': 'count', \n",
    "                              '_up_first_order_number': 'min', \n",
    "                              '_up_last_order_number':'max'}, \n",
    "              'add_to_cart_order':{'_up_average_cart_position': 'mean'}}\n",
    "\n",
    "data = ka_add_groupby_features_1_vs_n(df=priors_orders_detail, \n",
    "                                                      group_columns_list=['user_id', 'product_id'], \n",
    "                                                      agg_dict=agg_dict_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.merge(prd, how='inner', on='product_id').merge(users, how='inner', on='user_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "97ff9b86-233c-437f-987f-28fda714a064",
    "_execution_state": "idle",
    "_uuid": "a7001f50583b0f5f0297f8018ff8fcbf566255db"
   },
   "source": [
    "# Database Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3659d59a-f2b5-442a-85e4-99ed46844d9e",
    "_execution_state": "busy",
    "_uuid": "7958608441e2cc92445368f7ab7183280ac8d7f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add stats features begin ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/pandas/core/groupby.py:4036: FutureWarning: using a dict with renaming is deprecated and will be removed in a future version\n",
      "  return super(DataFrameGroupBy, self).aggregate(arg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add stats features end ......\n",
      "time lapsing 16.07272982597351 s \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 这里应该还有很多变量可以被添加\n",
    "# _up_order_count: 用户购买该商品的次数\n",
    "# _up_first_order_number: 用户第一次购买该商品所处的订单数\n",
    "# _up_last_order_number: 用户最后一次购买该商品所处的订单数\n",
    "# _up_average_cart_position: 该商品被添加到购物篮中的平均位置\n",
    "agg_dict_4 = {'order_number':{'_up_order_count': 'count', \n",
    "                              '_up_first_order_number': 'min', \n",
    "                              '_up_last_order_number':'max'}, \n",
    "              'add_to_cart_order':{'_up_average_cart_position': 'mean'}}\n",
    "\n",
    "data = ka_add_groupby_features_1_vs_n(df=priors_orders_detail, \n",
    "                                                      group_columns_list=['user_id', 'product_id'], \n",
    "                                                      agg_dict=agg_dict_4)\n",
    "\n",
    "data = data.merge(prd, how='inner', on='product_id').merge(users, how='inner', on='user_id')\n",
    "# 该商品购买次数 / 总的订单数\n",
    "# 最近一次购买商品 - 最后一次购买该商品\n",
    "# 该商品购买次数 / 第一次购买该商品到最后一次购买商品的的订单数\n",
    "data['_up_order_rate'] = data._up_order_count / data._user_total_orders\n",
    "data['_up_order_since_last_order'] = data._user_total_orders - data._up_last_order_number\n",
    "data['_up_order_rate_since_first_order'] = data._up_order_count / (data._user_total_orders - data._up_first_order_number + 1)\n",
    "\n",
    "# add user_id to train set\n",
    "train = train.merge(right=orders[['order_id', 'user_id']], how='left', on='order_id')\n",
    "data = data.merge(train[['user_id', 'product_id', 'reordered']], on=['user_id', 'product_id'], how='left')\n",
    "\n",
    "# release Memory\n",
    "# del train, prd, users\n",
    "# gc.collect()\n",
    "# release Memory\n",
    "del priors_orders_detail, orders\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['_up_order_rate'] = data._up_order_count / data._user_total_orders\n",
    "data['_up_order_since_last_order'] = data._user_total_orders - data._up_last_order_number\n",
    "data['_up_order_rate_since_first_order'] = data._up_order_count / (data._user_total_orders - data._up_first_order_number + 1)\n",
    "\n",
    "# add user_id to train set\n",
    "train = train.merge(right=orders[['order_id', 'user_id']], how='left', on='order_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.merge(train[['user_id', 'product_id', 'reordered']], on=['user_id', 'product_id'], how='left')\n",
    "\n",
    "# release Memory\n",
    "# del train, prd, users\n",
    "# gc.collect()\n",
    "# release Memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del priors_orders_detail, orders\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e9206cd4-138b-417a-9ec8-9b703bc89286",
    "_execution_state": "busy",
    "_uuid": "ffe7006fd12c8faf2463e7781a49d01b66b366cc",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0f016091-8029-4c63-a029-2829720e8890",
    "_execution_state": "idle",
    "_uuid": "81180a81e251ab065267a13fc9c62cd8c021b823"
   },
   "source": [
    "# Create Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7e211223-ce8d-4cfc-a9a3-48e6b70a9341",
    "_execution_state": "busy",
    "_uuid": "95989c977ec21519088e084c7b88cc89def05b1b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost\n",
    "\n",
    "train = data.loc[data.eval_set == \"train\",:]\n",
    "train.drop(['eval_set', 'user_id', 'product_id', 'order_id'], axis=1, inplace=True)\n",
    "train.loc[:, 'reordered'] = train.reordered.fillna(0)\n",
    "\n",
    "X_test = data.loc[data.eval_set == \"test\",:]\n",
    "\n",
    "# subsample 让training时间更短\n",
    "X_train, X_val, y_train, y_val = train_test_split(train.drop('reordered', axis=1), train.reordered,\n",
    "                                                    test_size=0.9, random_state=42)\n",
    "d_train = xgboost.DMatrix(X_train, y_train)\n",
    "xgb_params = {\n",
    "    \"objective\"         : \"reg:logistic\"\n",
    "    ,\"eval_metric\"      : \"logloss\"\n",
    "    ,\"eta\"              : 0.1\n",
    "    ,\"max_depth\"        : 6\n",
    "    ,\"min_child_weight\" :10\n",
    "    ,\"gamma\"            :0.70\n",
    "    ,\"subsample\"        :0.76\n",
    "    ,\"colsample_bytree\" :0.95\n",
    "    ,\"alpha\"            :2e-05\n",
    "    ,\"lambda\"           :10\n",
    "}\n",
    "\n",
    "watchlist= [(d_train, \"train\")]\n",
    "bst = xgboost.train(params=xgb_params, dtrain=d_train, num_boost_round=80, evals=watchlist, verbose_eval=10)\n",
    "xgboost.plot_importance(bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e17b046b-9165-4ca8-86ea-371f4092615a",
    "_execution_state": "busy",
    "_uuid": "d3d69878acb6d40f75c0ca499ac34a1879ad54f5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_test = xgboost.DMatrix(X_test.drop(['eval_set', 'user_id', 'order_id', 'reordered', 'product_id'], axis=1))\n",
    "X_test.loc[:,'reordered'] = (bst.predict(d_test) > 0.21).astype(int)\n",
    "X_test.loc[:, 'product_id'] = X_test.product_id.astype(str)\n",
    "submit = ka_add_groupby_features_n_vs_1(X_test[X_test.reordered == 1], \n",
    "                                               group_columns_list=['order_id'],\n",
    "                                               target_columns_list= ['product_id'],\n",
    "                                               methods_list=[lambda x: ' '.join(set(x))], keep_only_stats=True)\n",
    "submit.columns = sample_submission.columns.tolist()\n",
    "submit_final = sample_submission[['order_id']].merge(submit, how='left').fillna('None')\n",
    "submit_final.to_csv(\"python_test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
